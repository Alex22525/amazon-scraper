{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24fd5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from langdetect import detect\n",
    "import time\n",
    "from selenium.webdriver import Firefox, Chrome\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856095a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"sports\"\n",
    "base_url = \"https://amazon.com/\"\n",
    "# Fetch products for specific keyword\n",
    "def fetch_products_by_keyword(keyword):\n",
    "    driver = Chrome()\n",
    "    driver.maximize_window()\n",
    "    page_number = 0\n",
    "    while True:\n",
    "        page_number += 1\n",
    "        driver.get(base_url + \"s?k=\" + keyword + \"&page=\" + str(page_number) + \"&ref=nb_sb_noss_2\")\n",
    "        print(base_url + \"s?k=\" + keyword + \"&page=\" + str(page_number) + \"&ref=nb_sb_noss_2\")\n",
    "        products = driver.find_elements(By.XPATH, '//div[@data-component-type=\"s-search-result\"]')\n",
    "        for product in products:\n",
    "            with open(\"products_\" + keyword + \".txt\", \"a\") as file:\n",
    "                file.write(base_url + \"dp/\" + product.get_attribute(\"data-asin\") + \"\\n\")\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.XPATH, \"//a[@class='s-pagination-item s-pagination-next s-pagination-button s-pagination-separator']\")\n",
    "            time.sleep(5)\n",
    "        except Exception as ex:\n",
    "            print('Finished scraping keyword: ' + keyword)\n",
    "            break\n",
    "    driver.quit()\n",
    "fetch_products_by_keyword(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db620e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through products from txt file and fetch reviews for every comment\n",
    "def get_comments(fileName):\n",
    "    reviewedon, prodname = [],[]\n",
    "    file = open(fileName)\n",
    "    LIST=re.split(\"\\r\\n|\\n\",file.read())\n",
    "    file.close()\n",
    "    x = []\n",
    "    for i in LIST:\n",
    "        print(i.split('~')[-1])\n",
    "        x.append(i.split('~')[-1])\n",
    "    star_filter_on = True\n",
    "    star_filter_value = 5\n",
    "    comments = []\n",
    "    driver = Chrome()\n",
    "    df = pd.DataFrame()\n",
    "    driver.maximize_window()\n",
    "    i = 0\n",
    "    while i != len(x):\n",
    "\n",
    "        url = x[i]\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            product_name = url.split(\"/\")[3].replace(\"-\",\" \")\n",
    "            prodname.append(product_name)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "        try:\n",
    "            all_reviews = driver.find_element(By.CSS_SELECTOR,'#reviews-medley-footer .a-text-bold')\n",
    "            all_reviews.click()\n",
    "            # Check if star filter is on to just get reviews with specific star\n",
    "            if star_filter_on:\n",
    "                stars_list = driver.find_element(By.XPATH, '//span[@id=\"a-autoid-5-announce\"]')\n",
    "                stars_list.click()\n",
    "                choose_star = driver.find_element(By.XPATH, f'//a[@id=\"star-count-dropdown_{star_filter_value}\"]')\n",
    "                choose_star.click()\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "        while True:\n",
    "            lst_of_ratings = driver.find_elements(By.CLASS_NAME, \"review-rating\")\n",
    "            review_title = driver.find_elements(By.XPATH, \"//a[@data-hook='review-title']/span\")\n",
    "            loc_date = driver.find_elements(By.XPATH, \"//span[@data-hook='review-date']\")\n",
    "            review = driver.find_elements(By.XPATH, '//span[@data-hook=\"review-body\"]')\n",
    "            # reviewer = driver.find_elements(By.CSS_SELECTOR, '#cm_cr-review_list .a-profile-name')\n",
    "            try:\n",
    "                next_btn = driver.find_element(By.CSS_SELECTOR, \"#cm_cr-pagination_bar a\")\n",
    "            except:\n",
    "                pass\n",
    "            for k in range(len(review_title)):\n",
    "                try:\n",
    "                    date = loc_date[k].text.split('on')\n",
    "                except:\n",
    "                    pass  \n",
    "                reviewedon.append(date)\n",
    "                for value in lst_of_ratings:\n",
    "                    try:\n",
    "                        rating = value.get_attribute('textContent').split(\" \")[0]\n",
    "                    except:\n",
    "                        rating='Not Available!'\n",
    "                try:\n",
    "                    if review[k].text:\n",
    "                        check_lang = detect(review[k].text)\n",
    "                        if check_lang != 'en':\n",
    "                            print('Skipping non english comment')\n",
    "                            pass\n",
    "                    commentObj = {\n",
    "                        'review_title': review_title[k].text,\n",
    "                        'review_comment': review[k].text,\n",
    "                        'review_date': date,\n",
    "                        'review_rating': rating\n",
    "                    }\n",
    "                    comments.append(commentObj)\n",
    "                except:\n",
    "                    pass\n",
    "            try:\n",
    "                next_btn = driver.find_element(By.XPATH, \"//ul[@class='a-pagination']/li[2]/a\")\n",
    "                next_btn.click()\n",
    "                time.sleep(1)\n",
    "            except Exception as ex:\n",
    "                break\n",
    "        i+=1\n",
    "        \n",
    "    df = pd.DataFrame(comments)\n",
    "    df.to_csv(\"data.csv\", mode='a', index=False)\n",
    "    driver.close()\n",
    "    print(\"Finished with file: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d16b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_comments('products_controllers.txt')\n",
    "get_comments('products_playstation.txt')\n",
    "get_comments('products_video games.txt')\n",
    "get_comments('products_xbox.txt')\n",
    "get_comments('products_crafting.txt')\n",
    "get_comments('products_camera and photo.txt')\n",
    "get_comments('products_software.txt')\n",
    "get_comments('products_sports.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4adba7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will remove duplicate comments from csv file\n",
    "def clear_duplicate_comments(fileName):\n",
    "    data = pd.read_csv(fileName)\n",
    "    result = data.drop_duplicates(['review_comment'],keep='first')\n",
    "    result.to_csv(\"data-set-cleared.csv\",index=False)\n",
    "    \n",
    "clear_duplicate_comments(\"data-set.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
